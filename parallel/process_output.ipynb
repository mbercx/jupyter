{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the output into one datafile\n",
    "\n",
    "The function below was used to produce `.json` files for each of the systems we have studied. It can take a bit of time to run, as it needs to parse all the `OUTCAR`'s of the various calculations. Hence, directly loading the data from a `.json` file is faster, and that is used in [the parallel_analysis.ipynb notebook](parallel_analysis.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "\n",
    "from monty.re import regrep\n",
    "from monty.json import MontyEncoder\n",
    "from pymatgen import Structure\n",
    "from pymatgen.io.vasp.inputs import Incar\n",
    "from ipywidgets import interact, fixed, FloatSlider, Text\n",
    "\n",
    "data_dir = \"/mnt/data/mbercx/\"\n",
    "\n",
    "def process_parallel(data_dir, output_file=None, verbose=False):\n",
    "    timing_list = []\n",
    "\n",
    "    cores_pattern = r\"\\s+running\\son\\s+(\\S+)\\stotal\\scores\"\n",
    "    nkp_pattern = r\"k-points\\s+NKPTS\\s=\\s+([0-9]+)\\s+.*\"\n",
    "    nbands_pattern = r\".*NBANDS=\\s+([0-9]+)\"\n",
    "    loop_pattern = r\"\\s+LOOP:\\s+cpu\\stime.+:\\sreal\\stime(.+)\"\n",
    "    \n",
    "    n_kpoints = 0\n",
    "    nbands = 0\n",
    "    structure = None\n",
    "\n",
    "    for nodes_dir in os.listdir(data_dir):\n",
    "\n",
    "        nodes = int(nodes_dir.strip(\"nodes\"))\n",
    "\n",
    "        for kpar_dir in os.listdir(os.path.join(data_dir, nodes_dir)):\n",
    "\n",
    "            kpar = int(kpar_dir.strip(\"kpar\"))\n",
    "\n",
    "            for npar_dir in os.listdir(os.path.join(data_dir, nodes_dir, kpar_dir)):\n",
    "\n",
    "                npar = int(npar_dir.strip(\"npar\"))\n",
    "\n",
    "                nelmdl = np.abs(Incar.from_file(\n",
    "                    os.path.join(data_dir, nodes_dir, kpar_dir, npar_dir, \"INCAR\")\n",
    "                ).get(\"NELMDL\", 5))\n",
    "                \n",
    "                outcar_file = os.path.join(\n",
    "                    data_dir, nodes_dir, kpar_dir, npar_dir, \"OUTCAR\"\n",
    "                )\n",
    "                \n",
    "                if n_kpoints == 0:\n",
    "                    n_kpoints = int(regrep(\n",
    "                        outcar_file, {\"nkp\": nkp_pattern})[\"nkp\"][0][0][0])\n",
    "                    nbands = int(regrep(\n",
    "                        outcar_file, {\"nbands\": nbands_pattern})[\"nbands\"][0][0][0])\n",
    "                    structure = Structure.from_file(\n",
    "                        os.path.join(data_dir, nodes_dir, kpar_dir, npar_dir, \"POSCAR\")\n",
    "                    )\n",
    "\n",
    "                try:\n",
    "                    loop_timing = regrep(\n",
    "                        filename=outcar_file,\n",
    "                        patterns={\"loop\": loop_pattern})[\"loop\"]\n",
    "\n",
    "                    if len(loop_timing) > nelmdl:\n",
    "                        average_loop = np.mean([float(e[0][0]) for e in loop_timing][nelmdl:])\n",
    "                        total_cores = int(regrep(\n",
    "                            filename=outcar_file,\n",
    "                            patterns={\"cores\": cores_pattern})[\"cores\"][0][0][0])\n",
    "                        ncore = total_cores // kpar // npar\n",
    "\n",
    "                        timing_list.append(\n",
    "                            {\"nodes\": nodes, \"kpar\": kpar, \"ncore\": ncore,\n",
    "                             \"npar\": npar, \"timing\": average_loop}\n",
    "                        )\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(str(nodes) + \" \" + str(npar) + \" \"  \n",
    "                                  + str(kpar) + \" only has \" \n",
    "                                  + str(len(loop_timing)) + \" timesteps.\")\n",
    "                        \n",
    "                except FileNotFoundError:\n",
    "                    print(\"No OUTCAR file found for : \" + str(nodes) + \"nodes\"\n",
    "                          + \" \" + str(kpar) + \"kpar\" + \" \"  + str(npar) + \"npar\")\n",
    "\n",
    "    data = {\n",
    "        \"structure\": structure.as_dict(),\n",
    "        \"nbands\": nbands,\n",
    "        \"n_kpoints\": n_kpoints,\n",
    "        \"timing_list\": timing_list\n",
    "    }\n",
    "    \n",
    "    if output_file is None:\n",
    "        output_file = data_dir.split(\"/\")[4]\n",
    "        output_file += \"_\" + data_dir.split(\"/\")[5]\n",
    "        output_file += \"_\" + str(structure.composition).replace(\" \", \"\")\n",
    "        output_file += \"_B\" + str(nbands)\n",
    "        output_file += \"_K\" + str(n_kpoints)\n",
    "        output_file += \".json\"\n",
    "        output_file = os.path.join(\"data\", output_file)\n",
    "    \n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(json.dumps(data, cls=MontyEncoder))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below process each process one set of data into a corresponding json file and save it to the `data` directory.\n",
    "\n",
    "**Note: The notebook does not have access any of the `data_dir`'s used below when running on Binder. It it simply added to the repository for completeness.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leibniz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d1 in os.listdir(os.path.join(data_dir, \"leibniz\")):\n",
    "    for d2 in os.listdir(os.path.join(data_dir, \"leibniz\", d1)):\n",
    "        process_parallel(os.path.join(data_dir, \"leibniz\", d1, d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breniac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No OUTCAR file found for : 16nodes 2kpar 7npar\n"
     ]
    }
   ],
   "source": [
    "for d1 in os.listdir(os.path.join(data_dir, \"breniac\")):\n",
    "    for d2 in os.listdir(os.path.join(data_dir, \"breniac\", d1)):\n",
    "        process_parallel(os.path.join(data_dir, \"breniac\", d1, d2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_timing(data_dir, timing):\n",
    "    \n",
    "    loop_pattern = r\"\\s+LOOP:\\s+cpu\\stime.+:\\sreal\\stime(.+)\"\n",
    "    cores_pattern = r\"\\s+running\\son\\s+(\\S+)\\stotal\\scores\"\n",
    "    \n",
    "    outcar_file = os.path.join(\n",
    "        data_dir, str(timing[\"nodes\"]) + \"nodes\",\n",
    "        str(timing[\"kpar\"]) + \"kpar\",\n",
    "        str(timing[\"npar\"]) + \"npar\",\n",
    "        \"OUTCAR\"\n",
    "    )\n",
    "    incar = Incar.from_file(os.path.join(\n",
    "        data_dir, str(timing[\"nodes\"]) + \"nodes\",\n",
    "        str(timing[\"kpar\"]) + \"kpar\",\n",
    "        str(timing[\"npar\"]) + \"npar\",\n",
    "        \"INCAR\"\n",
    "    ))\n",
    "    nelmdl = abs(incar.get(\"NELMDL\", -5))\n",
    "    loop = regrep(outcar_file, {\"loop\": loop_pattern})[\"loop\"]\n",
    "    loop = np.array([float(l[0][0]) for l in loop[nelmdl:]])\n",
    "    cores = regrep(outcar_file, {\"cores\": cores_pattern})[\"cores\"]\n",
    "    cores = int(cores[0][0][0])\n",
    "    \n",
    "    time_check = np.mean(loop) - timing[\"timing\"] < 1e-4\n",
    "    cores_check = cores == timing[\"ncore\"]*timing[\"npar\"]*timing[\"kpar\"]\n",
    "    \n",
    "    return time_check, cores_check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for timing in data[\"timing_list\"]:\n",
    "    if not all(check_timing(data_dir=data_dir, timing=timing)):\n",
    "        print(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
